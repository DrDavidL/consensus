{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"paperId\": \"649def34f8be52c8b66281af98ae884c09aef38b\",\n",
      "    \"title\": \"Construction of the Literature Graph in Semantic Scholar\",\n",
      "    \"referenceCount\": 27,\n",
      "    \"citationCount\": 376\n",
      "  },\n",
      "  {\n",
      "    \"paperId\": \"f712fab0d58ae6492e3cdfc1933dae103ec12d5d\",\n",
      "    \"title\": \"Reinfection and low cross-immunity as drivers of epidemic resurgence under high seroprevalence: a model-based approach with application to Amazonas, Brazil\",\n",
      "    \"referenceCount\": 13,\n",
      "    \"citationCount\": 0\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'paperId': '649def34f8be52c8b66281af98ae884c09aef38b',\n",
       "  'title': 'Construction of the Literature Graph in Semantic Scholar',\n",
       "  'referenceCount': 27,\n",
       "  'citationCount': 299},\n",
       " {'paperId': 'f712fab0d58ae6492e3cdfc1933dae103ec12d5d',\n",
       "  'title': 'Reinfection and low cross-immunity as drivers of epidemic resurgence under high seroprevalence: a model-based approach with application to Amazonas, Brazil',\n",
       "  'referenceCount': 13,\n",
       "  'citationCount': 0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "    params={'fields': 'referenceCount,citationCount,title'},\n",
    "    json={\"ids\": [\"649def34f8be52c8b66281af98ae884c09aef38b\", \"ARXIV:2106.15928\"]}\n",
    ")\n",
    "print(json.dumps(r.json(), indent=2))\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"paperId\": \"649def34f8be52c8b66281af98ae884c09aef38b\",\n",
    "    \"title\": \"Construction of the Literature Graph in Semantic Scholar\",\n",
    "    \"referenceCount\": 27,\n",
    "    \"citationCount\": 299\n",
    "  },\n",
    "  {\n",
    "    \"paperId\": \"f712fab0d58ae6492e3cdfc1933dae103ec12d5d\",\n",
    "    \"title\": \"Reinfection and low cross-immunity as drivers of epidemic resurgence under high seroprevalence: a model-based approach with application to Amazonas, Brazil\",\n",
    "    \"referenceCount\": 13,\n",
    "    \"citationCount\": 0\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-mini-audio-preview\n",
      "o3-mini-2025-01-31\n",
      "o3-mini\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "o1-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "dall-e-2\n",
      "gpt-4o-2024-08-06\n",
      "o1\n",
      "gpt-3.5-turbo\n",
      "o1-preview-2024-09-12\n",
      "gpt-3.5-turbo-0125\n",
      "o1-preview\n",
      "text-embedding-ada-002\n",
      "o1-mini-2024-09-12\n",
      "gpt-4o\n",
      "whisper-1\n",
      "dall-e-3\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-4\n",
      "gpt-4-1106-preview\n",
      "babbage-002\n",
      "omni-moderation-latest\n",
      "omni-moderation-2024-09-26\n",
      "tts-1-hd-1106\n",
      "gpt-4o-2024-05-13\n",
      "tts-1-hd\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "chatgpt-4o-latest\n",
      "gpt-4-0613\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4-turbo\n",
      "tts-1\n",
      "tts-1-1106\n",
      "davinci-002\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-audio-preview\n",
      "text-embedding-3-small\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "text-embedding-3-large\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4-0125-preview\n",
      "o1-mini\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "models = client.models.list()\n",
    "for model in models:\n",
    "    print(model.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_completion(\n",
    "    messages,\n",
    "    google=False,\n",
    "    model=\"gpt-4o\",\n",
    "    frequency_penalty=0,\n",
    "    logit_bias=None,\n",
    "    logprobs=False,\n",
    "    top_logprobs=None,\n",
    "    max_tokens=None,\n",
    "    n=1,\n",
    "    presence_penalty=0,\n",
    "    response_format=None,\n",
    "    seed=None,\n",
    "    stop=None,\n",
    "    stream=False,\n",
    "    include_usage=False,\n",
    "    temperature=1,\n",
    "    tools=None,\n",
    "    tool_choice=\"none\",\n",
    "    user=None,\n",
    "    reasoning_effort=\"medium\"  # New parameter: accepts \"low\", \"medium\", or \"high\"\n",
    "):\n",
    "    if google:\n",
    "        client = OpenAI(\n",
    "            api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "        )\n",
    "        params = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"stream\": stream,\n",
    "            \"temperature\": temperature,\n",
    "        }\n",
    "    else:\n",
    "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        params = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"frequency_penalty\": frequency_penalty,\n",
    "            \"logit_bias\": logit_bias,\n",
    "            \"logprobs\": logprobs,\n",
    "            \"top_logprobs\": top_logprobs,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"n\": n,\n",
    "            \"presence_penalty\": presence_penalty,\n",
    "            \"response_format\": response_format,\n",
    "            \"seed\": seed,\n",
    "            \"stop\": stop,\n",
    "            \"stream\": stream,\n",
    "            \"temperature\": temperature,\n",
    "            \"user\": user,\n",
    "            \"response_format\": response_format,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    if model == \"o3-mini\":\n",
    "        # Insert the reasoning effort into the request parameters.\n",
    "        params[\"reasoning_effort\"] = reasoning_effort\n",
    "        params.pop(\"temperature\", None)\n",
    "    if stream:\n",
    "        params[\"stream_options\"] = {\"include_usage\": include_usage}\n",
    "    else:\n",
    "        params.pop(\"stream_options\", None)\n",
    "    if tools:\n",
    "        params[\"tools\"] = [{\"type\": \"function\", \"function\": tool} for tool in tools]\n",
    "        params[\"tool_choice\"] = tool_choice\n",
    "    if response_format == \"json_object\":\n",
    "        params[\"response_format\"] = {\"type\": \"json_object\"}\n",
    "    elif response_format == \"text\":\n",
    "        params[\"response_format\"] = {\"type\": \"text\"}\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "\n",
    "    completion = client.chat.completions.create(**params)\n",
    "\n",
    "    # If not streaming and usage details are available, extract reasoning tokens.\n",
    "    if not stream and \"usage\" in completion:\n",
    "        usage = completion.get(\"usage\", {})\n",
    "        completion_tokens_details = usage.get(\"completion_tokens_details\", {})\n",
    "        completion[\"reasoning_tokens\"] = completion_tokens_details.get(\"reasoning_tokens\")\n",
    "\n",
    "    return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'reasoning_effort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo3-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the capital of France?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[0;32mIn[7], line 74\u001b[0m, in \u001b[0;36mcreate_chat_completion\u001b[0;34m(messages, google, model, frequency_penalty, logit_bias, logprobs, top_logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, include_usage, temperature, tools, tool_choice, user, reasoning_effort)\u001b[0m\n\u001b[1;32m     71\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     72\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m---> 74\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# If not streaming and usage details are available, extract reasoning tokens.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m completion:\n",
      "File \u001b[0;32m~/Documents/GitHub/consensus/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'reasoning_effort'"
     ]
    }
   ],
   "source": [
    "response = create_chat_completion(model=\"o3-mini\", messages=[{\"role\": \"system\", \"content\": \"What is the capital of France?\"}], reasoning_effort=\"low\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"o3-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What are the GDMT meds for CHF?\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \n",
    "  ],\n",
    "  response_format={\n",
    "    \"type\": \"text\"\n",
    "  },\n",
    "  reasoning_effort=\"low\",\n",
    "  max_completion_tokens = 4000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guideline‐directed medical therapy (GDMT) for heart failure with reduced ejection fraction (HFrEF) is based on large clinical trials that have shown improved survival, reduced hospitalizations, and better quality of life. The key medication classes include:\n",
      "\n",
      "1. ACE Inhibitors (or ARBs/ARNIs)  \n",
      " • ACE Inhibitors (e.g., lisinopril, enalapril) help reduce afterload and remodeling.  \n",
      " • Angiotensin Receptor Blockers (ARBs, e.g., losartan, valsartan) are alternatives if ACE inhibitors aren’t tolerated.  \n",
      " • Angiotensin Receptor Neprilysin Inhibitors (ARNIs, e.g., sacubitril/valsartan) have shown additional benefits compared with ACE inhibitors and are recommended for eligible patients.\n",
      "\n",
      "2. Beta Blockers  \n",
      " • Beta blockers (e.g., carvedilol, metoprolol succinate, bisoprolol) reduce sympathetic activation, limit disease progression, and improve survival.\n",
      "\n",
      "3. Mineralocorticoid Receptor Antagonists (MRAs)  \n",
      " • MRAs (e.g., spironolactone, eplerenone) help counteract aldosterone’s effects, decreasing fibrosis and reducing hospitalizations and mortality.\n",
      "\n",
      "4. Sodium–Glucose Co-Transporter 2 (SGLT2) Inhibitors  \n",
      " • Originally developed for type 2 diabetes, agents such as dapagliflozin and empagliflozin have now been shown to improve outcomes in HFrEF regardless of diabetic status.\n",
      "\n",
      "Additional Considerations:\n",
      "\n",
      "• Diuretics (e.g., loop diuretics like furosemide) are an important adjunct to relieve congestion and symptoms, though they do not specifically reduce mortality.\n",
      "• In selected patients, other therapies (e.g., ivabradine, hydralazine/nitrates) may be considered based on individual patient factors like heart rate or race.\n",
      "• Optimization of GDMT is an evolving process—a patient’s regimen should be titrated to the maximum tolerated doses as supported by guidelines.\n",
      "\n",
      "Please note: The above medications are recommended specifically for HFrEF. For patients with heart failure with preserved ejection fraction (HFpEF), GDMT mainly focuses on controlling blood pressure and managing underlying conditions as there is less evidence for mortality-reducing therapies in that group.\n",
      "\n",
      "Always consult current guidelines (such as those from the American College of Cardiology/American Heart Association or European Society of Cardiology) and individualize therapy based on patient factors, comorbidities, and tolerance to medications.\n",
      "\n",
      "Was this overview helpful, or do you need further details on any of these classes?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "print(response.usage.completion_tokens_details.reasoning_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "r = requests.post(\n",
    "    'https://api.semanticscholar.org/graph/v1/paper/batch',\n",
    "    params={'fields': 'referenceCount,citationCount,title'},\n",
    "    json={\"ids\": [\"649def34f8be52c8b66281af98ae884c09aef38b\", \"ARXIV:2106.15928\"]}\n",
    ")\n",
    "print(json.dumps(r.json(), indent=2))\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"paperId\": \"649def34f8be52c8b66281af98ae884c09aef38b\",\n",
    "    \"title\": \"Construction of the Literature Graph in Semantic Scholar\",\n",
    "    \"referenceCount\": 27,\n",
    "    \"citationCount\": 299\n",
    "  },\n",
    "  {\n",
    "    \"paperId\": \"f712fab0d58ae6492e3cdfc1933dae103ec12d5d\",\n",
    "    \"title\": \"Reinfection and low cross-immunity as drivers of epidemic resurgence under high seroprevalence: a model-based approach with application to Amazonas, Brazil\",\n",
    "    \"referenceCount\": 13,\n",
    "    \"citationCount\": 0\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters for the Semantic Scholar API query\n",
    "api_base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "query = \"covid vaccination\"  # Default search query\n",
    "fields = \"title,authors,citations.abstract\"  # Default fields to return\n",
    "offset = 0  # Default offset for pagination\n",
    "limit = 3  # Default limit of results to return (must be <= 100)\n",
    "publication_types = \"JournalArticle\"  # Optional: e.g., \"JournalArticle,Review\"\n",
    "open_access_pdf = False  # Set to True to restrict to papers with open access PDFs\n",
    "min_citation_count = None  # Optional: minimum number of citations\n",
    "publication_date_or_year = None  # Optional: e.g., \"2016-03-05:2020-06-06\"\n",
    "year = \"2023\"  # Optional: e.g., \"2016-2020\"\n",
    "venue = None  # Optional: e.g., \"Nature,Radiology\"\n",
    "fields_of_study = None  # Optional: e.g., \"Physics,Mathematics\"\n",
    "\n",
    "# Construct the query parameters\n",
    "params = {\n",
    "    \"query\": query,\n",
    "    \"fields\": fields,\n",
    "    \"offset\": offset,\n",
    "    \"limit\": limit\n",
    "}\n",
    "\n",
    "# Add optional parameters if specified\n",
    "if publication_types:\n",
    "    params[\"publicationTypes\"] = publication_types\n",
    "if open_access_pdf:\n",
    "    params[\"openAccessPdf\"] = \"\"\n",
    "if min_citation_count is not None:\n",
    "    params[\"minCitationCount\"] = min_citation_count\n",
    "if publication_date_or_year:\n",
    "    params[\"publicationDateOrYear\"] = publication_date_or_year\n",
    "if year:\n",
    "    params[\"year\"] = year\n",
    "if venue:\n",
    "    params[\"venue\"] = venue\n",
    "if fields_of_study:\n",
    "    params[\"fieldsOfStudy\"] = fields_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers found: 154992\n",
      "\n",
      "Paper ID: df72552a9579aac7e1b3f9ef25d6f1b9ee675d20\n",
      "Title: Long COVID risk and pre-COVID vaccination in an EHR-based cohort study from the RECOVER program\n",
      "Authors: M. Brannock, Robert F. Chew, Alexander J. Preiss, Emily C Hadley, Signe Redfield, J. McMurry, Peter J Leese, A. Girvin, M. Crosskey, A. Zhou, R. Moffitt, M. J. Funk, E. Pfaff, M. Haendel, C. Chute\n",
      "\n",
      "Paper ID: 3a309f89ad7f1a9b3fa8de16e7231a15487756c8\n",
      "Title: Connectedness of COVID vaccination with economic policy uncertainty, oil, bonds, and sectoral equity markets: evidence from the US\n",
      "Authors: Imran Yousaf, Saba Qureshi, Fiza Qureshi, Mariya Gubareva\n",
      "\n",
      "Paper ID: 115238ce0d461c22fa4fe0556c21d02263ffc11b\n",
      "Title: The impact of COVID-19 and COVID vaccination on cardiovascular outcomes\n",
      "Authors: Zubair Akhtar, Mallory J. Trent, A. Moa, T. Tan, Ole Fröbert, C. Macintyre\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Execute the API query\n",
    "response = requests.get(api_base_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    total_papers = data.get(\"total\", 0)\n",
    "    papers = data.get(\"data\", [])\n",
    "    \n",
    "    # Display the total number of papers found\n",
    "    print(f\"Total papers found: {total_papers}\")\n",
    "    \n",
    "    # Display information about each paper\n",
    "    for paper in papers:\n",
    "        paper_id = paper.get(\"paperId\", \"N/A\")\n",
    "        title = paper.get(\"title\", \"N/A\")\n",
    "        authors = \", \".join([author.get(\"name\", \"N/A\") for author in paper.get(\"authors\", [])])\n",
    "        print(f\"\\nPaper ID: {paper_id}\\nTitle: {title}\\nAuthors: {authors}\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters for the Semantic Scholar API query\n",
    "api_base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "query = \"covid vaccination\"  # Default search query\n",
    "fields = \"title,authors\"  # Default fields to return\n",
    "offset = 0  # Default offset for pagination\n",
    "limit = 3  # Default limit of results to return (must be <= 100)\n",
    "publication_types = \"\"  # Optional: e.g., \"JournalArticle,Review\"\n",
    "open_access_pdf = False  # Set to True to restrict to papers with open access PDFs\n",
    "min_citation_count = None  # Optional: minimum number of citations\n",
    "publication_date_or_year = None  # Optional: e.g., \"2016-03-05:2020-06-06\"\n",
    "year = None  # Optional: e.g., \"2016-2020\"\n",
    "venue = None  # Optional: e.g., \"Nature,Radiology\"\n",
    "fields_of_study = None  # Optional: e.g., \"Physics,Mathematics\"\n",
    "\n",
    "# Construct the query parameters\n",
    "params = {\n",
    "    \"query\": query,\n",
    "    \"fields\": fields,\n",
    "    \"offset\": offset,\n",
    "    \"limit\": limit\n",
    "}\n",
    "\n",
    "# Add optional parameters if specified\n",
    "if publication_types:\n",
    "    params[\"publicationTypes\"] = publication_types\n",
    "if open_access_pdf:\n",
    "    params[\"openAccessPdf\"] = \"\"\n",
    "if min_citation_count is not None:\n",
    "    params[\"minCitationCount\"] = min_citation_count\n",
    "if publication_date_or_year:\n",
    "    params[\"publicationDateOrYear\"] = publication_date_or_year\n",
    "if year:\n",
    "    params[\"year\"] = year\n",
    "if venue:\n",
    "    params[\"venue\"] = venue\n",
    "if fields_of_study:\n",
    "    params[\"fieldsOfStudy\"] = fields_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers found: 1361432\n",
      "Error retrieving details for paper ID df72552a9579aac7e1b3f9ef25d6f1b9ee675d20: 429\n",
      "\n",
      "Paper ID: 3a309f89ad7f1a9b3fa8de16e7231a15487756c8\n",
      "Title: Connectedness of COVID vaccination with economic policy uncertainty, oil, bonds, and sectoral equity markets: evidence from the US\n",
      "Authors: Imran Yousaf, Saba Qureshi, Fiza Qureshi, Mariya Gubareva\n",
      "URL: https://www.semanticscholar.org/paper/3a309f89ad7f1a9b3fa8de16e7231a15487756c8\n",
      "External IDs: {'PubMedCentral': '10032274', 'DOI': '10.1007/s10479-023-05267-9', 'CorpusId': 257712018, 'PubMed': '37361093'}\n",
      "\n",
      "Paper ID: 115238ce0d461c22fa4fe0556c21d02263ffc11b\n",
      "Title: The impact of COVID-19 and COVID vaccination on cardiovascular outcomes\n",
      "Authors: Zubair Akhtar, Mallory J. Trent, A. Moa, T. Tan, Ole Fröbert, C. Macintyre\n",
      "URL: https://www.semanticscholar.org/paper/115238ce0d461c22fa4fe0556c21d02263ffc11b\n",
      "External IDs: {'PubMedCentral': '10021497', 'DOI': '10.1093/eurheartjsupp/suac123', 'CorpusId': 256918421, 'PubMed': '36937372'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Execute the initial API query to search for papers\n",
    "response = requests.get(api_base_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    total_papers = data.get(\"total\", 0)\n",
    "    papers = data.get(\"data\", [])\n",
    "    \n",
    "    # Display the total number of papers found\n",
    "    print(f\"Total papers found: {total_papers}\")\n",
    "    \n",
    "    # Base URL for retrieving paper details\n",
    "    paper_details_base_url = \"https://api.semanticscholar.org/graph/v1/paper/\"\n",
    "    \n",
    "    # Iterate over each paper to retrieve additional details\n",
    "    for paper in papers:\n",
    "        paper_id = paper.get(\"paperId\", \"N/A\")\n",
    "        \n",
    "        # Request additional details for each paper, including URL and external IDs\n",
    "        paper_details_response = requests.get(\n",
    "            f\"{paper_details_base_url}{paper_id}\",\n",
    "            params={\"fields\": \"title,authors,url,externalIds\"}\n",
    "        )\n",
    "        \n",
    "        if paper_details_response.status_code == 200:\n",
    "            paper_details = paper_details_response.json()\n",
    "            title = paper_details.get(\"title\", \"N/A\")\n",
    "            authors = \", \".join([author.get(\"name\", \"N/A\") for author in paper_details.get(\"authors\", [])])\n",
    "            url = paper_details.get(\"url\", \"N/A\")\n",
    "            external_ids = paper_details.get(\"externalIds\", {})\n",
    "            \n",
    "            # Display each paper's information followed by its URL and external IDs\n",
    "            print(f\"\\nPaper ID: {paper_id}\\nTitle: {title}\\nAuthors: {authors}\\nURL: {url}\\nExternal IDs: {external_ids}\")\n",
    "        else:\n",
    "            print(f\"Error retrieving details for paper ID {paper_id}: {paper_details_response.status_code}\")\n",
    "        \n",
    "        # Wait for one second to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters for the Semantic Scholar API query\n",
    "api_base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "query = \"covid vaccination\"  # Default search query\n",
    "fields = \"title,authors\"  # Default fields to return\n",
    "offset = 0  # Default offset for pagination\n",
    "limit = 3  # Default limit of results to return (must be <= 100)\n",
    "publication_types = \"\"  # Optional: e.g., \"JournalArticle,Review\"\n",
    "open_access_pdf = False  # Set to True to restrict to papers with open access PDFs\n",
    "min_citation_count = None  # Optional: minimum number of citations\n",
    "publication_date_or_year = None  # Optional: e.g., \"2016-03-05:2020-06-06\"\n",
    "year = None  # Optional: e.g., \"2016-2020\"\n",
    "venue = None  # Optional: e.g., \"Nature,Radiology\"\n",
    "fields_of_study = None  # Optional: e.g., \"Physics,Mathematics\"\n",
    "\n",
    "# Construct the query parameters\n",
    "params = {\n",
    "    \"query\": query,\n",
    "    \"fields\": fields,\n",
    "    \"offset\": offset,\n",
    "    \"limit\": limit\n",
    "}\n",
    "\n",
    "# Add optional parameters if specified\n",
    "if publication_types:\n",
    "    params[\"publicationTypes\"] = publication_types\n",
    "if open_access_pdf:\n",
    "    params[\"openAccessPdf\"] = \"\"\n",
    "if min_citation_count is not None:\n",
    "    params[\"minCitationCount\"] = min_citation_count\n",
    "if publication_date_or_year:\n",
    "    params[\"publicationDateOrYear\"] = publication_date_or_year\n",
    "if year:\n",
    "    params[\"year\"] = year\n",
    "if venue:\n",
    "    params[\"venue\"] = venue\n",
    "if fields_of_study:\n",
    "    params[\"fieldsOfStudy\"] = fields_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers found: 1361433\n",
      "Error retrieving details for paper ID df72552a9579aac7e1b3f9ef25d6f1b9ee675d20: 429\n",
      "\n",
      "Paper ID: 3a309f89ad7f1a9b3fa8de16e7231a15487756c8\n",
      "Title: Connectedness of COVID vaccination with economic policy uncertainty, oil, bonds, and sectoral equity markets: evidence from the US\n",
      "Authors: Imran Yousaf, Saba Qureshi, Fiza Qureshi, Mariya Gubareva\n",
      "URL: https://www.semanticscholar.org/paper/3a309f89ad7f1a9b3fa8de16e7231a15487756c8\n",
      "External IDs: {'PubMedCentral': '10032274', 'DOI': '10.1007/s10479-023-05267-9', 'CorpusId': 257712018, 'PubMed': '37361093'}\n",
      "Error retrieving details for paper ID 115238ce0d461c22fa4fe0556c21d02263ffc11b: 429\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Execute the initial API query to search for papers\n",
    "response = requests.get(api_base_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    total_papers = data.get(\"total\", 0)\n",
    "    papers = data.get(\"data\", [])\n",
    "    \n",
    "    # Display the total number of papers found\n",
    "    print(f\"Total papers found: {total_papers}\")\n",
    "    \n",
    "    # Base URL for retrieving paper details\n",
    "    paper_details_base_url = \"https://api.semanticscholar.org/graph/v1/paper/\"\n",
    "    \n",
    "    # List to store detailed paper information\n",
    "    detailed_papers_info = []\n",
    "    \n",
    "    # Iterate over each paper to retrieve additional details\n",
    "    for paper in papers:\n",
    "        paper_id = paper.get(\"paperId\", \"N/A\")\n",
    "        \n",
    "        # Request additional details for each paper, including URL and external IDs\n",
    "        paper_details_response = requests.get(\n",
    "            f\"{paper_details_base_url}{paper_id}\",\n",
    "            params={\"fields\": \"title,authors,url,externalIds,citations\"}\n",
    "        )\n",
    "        \n",
    "        if paper_details_response.status_code == 200:\n",
    "            paper_details = paper_details_response.json()\n",
    "            title = paper_details.get(\"title\", \"N/A\")\n",
    "            authors = \", \".join([author.get(\"name\", \"N/A\") for author in paper_details.get(\"authors\", [])])\n",
    "            url = paper_details.get(\"url\", \"N/A\")\n",
    "            external_ids = paper_details.get(\"externalIds\", {})\n",
    "            citations = paper_details.get(\"citations\", [])\n",
    "            \n",
    "            # Store the detailed paper information\n",
    "            detailed_papers_info.append({\n",
    "                \"paperId\": paper_id,\n",
    "                \"title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"url\": url,\n",
    "                \"externalIds\": external_ids,\n",
    "                \"citations\": citations\n",
    "            })\n",
    "            \n",
    "            # Display each paper's information followed by its URL and external IDs\n",
    "            print(f\"\\nPaper ID: {paper_id}\\nTitle: {title}\\nAuthors: {authors}\\nURL: {url}\\nExternal IDs: {external_ids}\")\n",
    "        else:\n",
    "            print(f\"Error retrieving details for paper ID {paper_id}: {paper_details_response.status_code}\")\n",
    "        \n",
    "        # Wait for one second to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Citation URLs:\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a URL based on the preferred order of external IDs\n",
    "def generate_preferred_url(external_ids):\n",
    "    if 'PubMedCentral' in external_ids:\n",
    "        return f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{external_ids['PubMedCentral']}/\"\n",
    "    elif 'DOI' in external_ids:\n",
    "        return f\"https://doi.org/{external_ids['DOI']}\"\n",
    "    elif 'CorpusId' in external_ids:\n",
    "        return f\"https://www.semanticscholar.org/paper/{external_ids['CorpusId']}\"\n",
    "    elif 'PubMed' in external_ids:\n",
    "        return f\"https://pubmed.ncbi.nlm.nih.gov/{external_ids['PubMed']}/\"\n",
    "    return None\n",
    "\n",
    "# Process each paper's citations to generate a list of URLs\n",
    "citation_urls = []\n",
    "for paper_info in detailed_papers_info:\n",
    "    for citation in paper_info.get(\"citations\", []):\n",
    "        citation_external_ids = citation.get(\"externalIds\", {})\n",
    "        citation_url = generate_preferred_url(citation_external_ids)\n",
    "        if citation_url:\n",
    "            citation_urls.append(citation_url)\n",
    "\n",
    "# Display the list of URLs\n",
    "print(\"\\nCitation URLs:\")\n",
    "for url in citation_urls:\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
